{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "sys.path.insert(0, \"/home/anonymous/Desktop/eeg_sampling/modeling\")\n",
    "from dataio import readdata, readlabels, writedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: (453, 480, 8) (453,)\n",
      "Testing: (113, 480, 8) (113,)\n"
     ]
    }
   ],
   "source": [
    "#Read training\n",
    "train_dataset = readdata(\"./../curated/train_dataset\")\n",
    "train_labels = readlabels(\"./../curated/train_labels\")\n",
    "#Read validation\n",
    "#valid_dataset = readdata(\"./curated/valid_dataset\")\n",
    "#valid_labels = readlabels(\"./curated/valid_labels\")\n",
    "#Read test\n",
    "test_dataset = readdata(\"./../curated/test_dataset\")\n",
    "test_labels = readlabels(\"./../curated/test_labels\")\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "#print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_input = 8*480 # EEG data input (8 channels * 360 sample points)\n",
    "n_classes = 3 # EEG total classes (\"nothing\", \"up\", \"down\", \"left\", \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(453, 3840)\n",
      "(113, 3840)\n"
     ]
    }
   ],
   "source": [
    "train_dataset.shape = (train_dataset.shape[0], n_input)\n",
    "test_dataset.shape = (test_dataset.shape[0], n_input)\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn Acc:  0.371681415929\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "knn = KNeighborsClassifier(\n",
    "    algorithm=\"auto\", \n",
    "    weights=\"uniform\", \n",
    "    n_neighbors=15)\n",
    "knn.fit(train_dataset, train_labels)\n",
    "knn_pred = knn.predict(test_dataset)\n",
    "knn_acc = accuracy_score(test_labels, knn_pred)\n",
    "print(\"Knn Acc: \", knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lda Acc:  0.398230088496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "lda = LinearDiscriminantAnalysis(\n",
    "    solver=\"svd\",\n",
    "    store_covariance=False,\n",
    "    tol = 0.0001)\n",
    "lda.fit(train_dataset, train_labels)\n",
    "lda_pred = lda.predict(test_dataset)\n",
    "lda_acc = accuracy_score(test_labels, lda_pred)\n",
    "print(\"Lda Acc: \", lda_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Acc:  0.318584070796\n"
     ]
    }
   ],
   "source": [
    "#Random Forests\n",
    "forest = ExtraTreesClassifier(n_estimators = 1000)\n",
    "forest.fit(train_dataset, train_labels)\n",
    "forest_pred = forest.predict(test_dataset)\n",
    "forest_acc = accuracy_score(test_labels, forest_pred)\n",
    "print(\"For Acc: \", forest_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svm Acc:  0.380530973451\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm_mod = svm.LinearSVC(\n",
    "    C=1.0,\n",
    "    penalty=\"l2\",\n",
    "    loss=\"squared_hinge\",\n",
    "    tol=0.0001)\n",
    "svm_mod.fit(train_dataset, train_labels)\n",
    "svm_pred = svm_mod.predict(test_dataset)\n",
    "svm_acc = accuracy_score(test_labels, svm_pred)\n",
    "print(\"Svm Acc: \", svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ada Acc:  0.336283185841\n"
     ]
    }
   ],
   "source": [
    "#Ada\n",
    "ada = AdaBoostClassifier(n_estimators = 50)\n",
    "ada.fit(train_dataset, train_labels)\n",
    "ada_pred = ada.predict(test_dataset)\n",
    "ada_acc = accuracy_score(test_labels, ada_pred)\n",
    "print(\"Ada Acc: \", ada_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lgr Acc:  0.380530973451\n"
     ]
    }
   ],
   "source": [
    "#Logistic\n",
    "lgr = linear_model.LogisticRegression()\n",
    "lgr.fit(train_dataset, train_labels)\n",
    "lgr_pred = lgr.predict(test_dataset)\n",
    "lgr_acc = accuracy_score(test_labels, lgr_pred)\n",
    "print(\"Lgr Acc: \", lgr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './predicting/model/eeg.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a02c61a477f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Save Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./predicting/model/eeg.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, cache_size, protocol)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         pickler = NumpyPickler(filename, compress=compress,\n\u001b[1;32m--> 405\u001b[1;33m                                cache_size=cache_size, protocol=protocol)\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0mpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib64/python3.4/site-packages/sklearn/externals/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, compress, cache_size, protocol)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './predicting/model/eeg.model'"
     ]
    }
   ],
   "source": [
    "#Save Model\n",
    "joblib.dump(forest, './predicting/model/eeg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read Model\n",
    "forest = joblib.load('./predicting/model/eeg.model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forest_pred = forest.predict(test_dataset)\n",
    "forest_acc = accuracy_score(test_labels, forest_pred)\n",
    "print(forest_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Voting\n",
    "vot = VotingClassifier(estimators=[\n",
    "        (\"KNN\", knn),\n",
    "        (\"LDA\", lda),\n",
    "        (\"FOR\", forest),\n",
    "        (\"SVM\", svm_mod),\n",
    "        (\"ADA\", ada),\n",
    "        (\"LGR\", lgr)\n",
    "    ], voting = \"hard\", weights=[6,0,5,1,1,1])\n",
    "vot.fit(train_dataset, train_labels)\n",
    "vot_pred = vot.predict(test_dataset)\n",
    "print(accuracy_score(test_labels, vot_pred))\n",
    "print(vot_pred)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the classifier\n",
    "with open('./predicting/eeg.model', 'wb') as writestream:\n",
    "    pickle.dump(forest, writestream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from dataio import readdata, readlabels, writedata\n",
    "# load it again\n",
    "with open('./predicting/eeg.model', 'rb') as readstream:\n",
    "    clf = pickle.load(readstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_pred = clf.predict(train_dataset)\n",
    "print(clf_pred)\n",
    "print(train_labels)\n",
    "#print(accuracy_score(train_labels, clf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1291, 20)\n",
      "(30, 20)\n"
     ]
    }
   ],
   "source": [
    "#PCA \n",
    "pca = PCA(n_components=20)\n",
    "train_dataset = pca.fit_transform(train_dataset)\n",
    "test_dataset = pca.fit_transform(test_dataset)\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SGD\n",
    "clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\")\n",
    "clf.fit(train_dataset, train_labels)\n",
    "clf_pred = clf.predict(test_dataset)\n",
    "accuracy_score(test_labels, clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistic\n",
    "clf = linear_model.Perceptron(n_iter=100)\n",
    "clf.fit(train_dataset, train_labels)\n",
    "clf_pred = clf.predict(test_dataset)\n",
    "clf_acc = accuracy_score(test_labels, clf_pred)\n",
    "print(clf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bags\n",
    "knn = BaggingClassifier(KNeighborsClassifier(\n",
    "    algorithm=\"auto\", \n",
    "    weights=\"uniform\", \n",
    "    n_neighbors=15), max_samples=0.5, max_features=0.5)\n",
    "knn.fit(train_dataset, train_labels)\n",
    "knn_pred = knn.predict(test_dataset)\n",
    "knn_acc = accuracy_score(test_labels, knn_pred)\n",
    "print(knn_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
