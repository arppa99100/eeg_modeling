{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check librosa stft and istft\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "sys.path.insert(0, \"/home/anonymous/Desktop/eeg_sampling/modeling\")\n",
    "from dataio import readdata2, readlabels2, writedata\n",
    "from datafilters import apply_dc_filter, apply_dwt_filter, apply_stfft_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparams\n",
    "\n",
    "#DC Filter\n",
    "enable_dc = True\n",
    "dc_lowcut = 1.0\n",
    "dc_highcut = 13.0\n",
    "dc_order = 2\n",
    "dc_type = \"bandpass\"\n",
    "dc_func_type = \"butter\"\n",
    "\n",
    "#DWT Filter\n",
    "enable_dwt = False\n",
    "dwt_type = \"db2\"\n",
    "dwt_level = 4\n",
    "dwt_thresh_func = \"soft\"\n",
    "dwt_thresh_type = \"rigrsure\"\n",
    "\n",
    "#STFT Filter\n",
    "enable_fft = False\n",
    "fft_window = 0.50\n",
    "fft_step = 0.25\n",
    "fft_thresh = 2.0\n",
    "fft_set_thresh = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predataset = readdata2(\"./../curated/raw-presamples\")\n",
    "dataset = readdata2(\"./../curated/raw-samples\")\n",
    "labels = readlabels2(\"./../curated/raw-inputs\")\n",
    "#Constants\n",
    "fs = 250.0 #Frequency in Hz\n",
    "sample_time = dataset[0].shape[1]/fs #Total time for sample\n",
    "presample_time = predataset[0].shape[1]/fs #Total time for sample\n",
    "num_rows = 360 \n",
    "num_channels = 8\n",
    "\n",
    "total_samples = 0\n",
    "for k in range(0, len(dataset)):\n",
    "    predataset[k].flags['WRITEABLE'] = True\n",
    "    dataset[k].flags['WRITEABLE'] = True\n",
    "    total_samples += dataset[k].shape[0]\n",
    "    for i in range(0,dataset[k].shape[0]):\n",
    "        for j in range(0,dataset[k].shape[2]):\n",
    "            if enable_dc:\n",
    "                predataset[k][i,:,j] = apply_dc_filter(predataset[k][i,:,j], fs, dc_lowcut, dc_highcut, dc_order, dc_type, dc_func_type)\n",
    "                dataset[k][i,:,j] = apply_dc_filter(dataset[k][i,:,j], fs, dc_lowcut, dc_highcut, dc_order, dc_type, dc_func_type)\n",
    "            if enable_dwt:\n",
    "                predataset[k][i,:,j] = apply_dwt_filter(predataset[k][i,:,j], dwt_type, dwt_level, dwt_thresh_func, dwt_thresh_type)\n",
    "                dataset[k][i,:,j] = apply_dwt_filter(dataset[k][i,:,j], dwt_type, dwt_level, dwt_thresh_func, dwt_thresh_type)\n",
    "            if enable_fft:\n",
    "                predataset[k][i,:,j] = apply_stfft_filter(predataset[k][i,:,j], fs, presample_time, fft_window, fft_step, fft_thresh, fft_set_thresh)\n",
    "                dataset[k][i,:,j] = apply_stfft_filter(dataset[k][i,:,j], fs, sample_time, fft_window, fft_step, fft_thresh, fft_set_thresh)\n",
    "            #Normalize\n",
    "            dataset[k][i,:,j] = dataset[k][i,:,j]/np.linalg.norm(dataset[k][i,:,j])\n",
    "            #predataset[k][i,:,j] = predataset[k][i,:,j]/np.linalg.norm(predataset[k][i,:,j])\n",
    "            #np.mean(predataset[k][i,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_idx = np.random.random_integers(0,len(dataset)-1,1)\n",
    "test_dataset = dataset.pop(test_idx[0])\n",
    "test_labels = labels.pop(test_idx[0])\n",
    "\n",
    "train_dataset = np.concatenate(dataset)\n",
    "train_dataset.shape = (total_samples - test_dataset.shape[0], num_rows, num_channels)\n",
    "train_labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './curated/train_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5ffc3788512b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Write training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mwritedata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./curated/train_dataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwritedata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./curated/train_labels\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Write validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#writedata(\"./curated/valid_dataset\", valid_dataset)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/anonymous/Desktop/eeg_sampling/modeling/dataio.py\u001b[0m in \u001b[0;36mwritedata\u001b[1;34m(pathname, data)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m   \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwritestream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0mwritestream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt_i32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mwritestream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './curated/train_dataset'"
     ]
    }
   ],
   "source": [
    "#Write training\n",
    "writedata(\"./../curated/train_dataset\", train_dataset)\n",
    "writedata(\"./../curated/train_labels\", train_labels)\n",
    "#Write validation\n",
    "#writedata(\"./curated/valid_dataset\", valid_dataset)\n",
    "#writedata(\"./curated/valid_labels\", valid_labels)\n",
    "#Write test\n",
    "writedata(\"./curated/test_dataset\", test_dataset)\n",
    "writedata(\"./curated/test_labels\", test_labels)\n",
    "#plt.figure(figsize=(15,8))\n",
    "#plt.plot(dataset[0,:,0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250,)\n",
      "(1250, 360, 8)\n",
      "(71, 360, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
